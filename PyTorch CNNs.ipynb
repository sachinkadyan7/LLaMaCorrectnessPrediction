{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d8fb0b4-a0fd-4489-8b07-acda5f4e0dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.models import convnext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a2001f3-8a56-410d-a76b-3f141a2876d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNeXt(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
       "      (1): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=96, out_features=384, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=384, out_features=96, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "      )\n",
       "      (1): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=96, out_features=384, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=384, out_features=96, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0058823529411764705, mode=row)\n",
       "      )\n",
       "      (2): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=96, out_features=384, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=384, out_features=96, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.011764705882352941, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
       "      (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=192, out_features=768, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=768, out_features=192, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.017647058823529415, mode=row)\n",
       "      )\n",
       "      (1): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=192, out_features=768, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=768, out_features=192, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.023529411764705882, mode=row)\n",
       "      )\n",
       "      (2): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=192, out_features=768, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=768, out_features=192, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.029411764705882353, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.03529411764705883, mode=row)\n",
       "      )\n",
       "      (1): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0411764705882353, mode=row)\n",
       "      )\n",
       "      (2): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.047058823529411764, mode=row)\n",
       "      )\n",
       "      (3): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.052941176470588235, mode=row)\n",
       "      )\n",
       "      (4): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.058823529411764705, mode=row)\n",
       "      )\n",
       "      (5): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.06470588235294118, mode=row)\n",
       "      )\n",
       "      (6): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.07058823529411766, mode=row)\n",
       "      )\n",
       "      (7): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.07647058823529412, mode=row)\n",
       "      )\n",
       "      (8): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0823529411764706, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.08823529411764706, mode=row)\n",
       "      )\n",
       "      (1): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.09411764705882353, mode=row)\n",
       "      )\n",
       "      (2): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): LayerNorm2d((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "    (2): Linear(in_features=768, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torchvision.models.convnext_tiny(weights=convnext.ConvNeXt_Tiny_Weights.DEFAULT)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f5b8a6f-eda3-4ee8-ad4a-7b1206a7622f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0510, 0.0667, 0.0588,  ..., 0.0745, 0.0784, 0.0706],\n",
       "         [0.0627, 0.0706, 0.0588,  ..., 0.0745, 0.0902, 0.0824],\n",
       "         [0.0667, 0.0706, 0.0667,  ..., 0.0667, 0.0902, 0.0863],\n",
       "         ...,\n",
       "         [0.4039, 0.2824, 0.2235,  ..., 0.2510, 0.3412, 0.4863],\n",
       "         [0.4353, 0.3373, 0.2863,  ..., 0.2588, 0.2980, 0.3725],\n",
       "         [0.3686, 0.2784, 0.2627,  ..., 0.2118, 0.2235, 0.2980]],\n",
       "\n",
       "        [[0.1176, 0.1333, 0.1137,  ..., 0.1216, 0.1294, 0.1216],\n",
       "         [0.1059, 0.1137, 0.1020,  ..., 0.1216, 0.1373, 0.1294],\n",
       "         [0.0902, 0.0941, 0.0902,  ..., 0.1137, 0.1373, 0.1333],\n",
       "         ...,\n",
       "         [0.4863, 0.3843, 0.3451,  ..., 0.3686, 0.4196, 0.5294],\n",
       "         [0.4824, 0.3922, 0.3647,  ..., 0.3765, 0.3569, 0.4000],\n",
       "         [0.4157, 0.3333, 0.3412,  ..., 0.3294, 0.2824, 0.3255]],\n",
       "\n",
       "        [[0.0471, 0.0706, 0.0549,  ..., 0.0667, 0.0902, 0.0824],\n",
       "         [0.0745, 0.0902, 0.0784,  ..., 0.0431, 0.0588, 0.0510],\n",
       "         [0.0745, 0.0784, 0.0745,  ..., 0.0353, 0.0588, 0.0549],\n",
       "         ...,\n",
       "         [0.3569, 0.2471, 0.2196,  ..., 0.2588, 0.2824, 0.4039],\n",
       "         [0.3882, 0.3020, 0.2667,  ..., 0.2667, 0.2275, 0.2784],\n",
       "         [0.3216, 0.2431, 0.2431,  ..., 0.2196, 0.1529, 0.2039]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "from PIL import Image\n",
    "input_image = Image.open(\"dog.jpg\")\n",
    "input_tensor = preprocess(input_image)\n",
    "input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b2a993c-666f-4b27-adfd-e0f878bcfb5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 7.4499e-02,  2.6175e-01, -3.7133e-01, -4.0203e-01, -4.7379e-01,\n",
      "         8.9643e-02,  1.7304e-01,  4.1468e-01,  5.9469e-01,  2.5760e-01,\n",
      "         7.0624e-01,  3.3094e-01,  2.3178e-01,  8.5878e-01,  3.3874e-01,\n",
      "         3.8268e-01,  1.8625e-01,  1.6838e-01,  1.1058e+00,  6.1064e-01,\n",
      "         5.3451e-01,  2.2470e-01,  1.9841e-01,  9.0423e-01,  2.9987e-01,\n",
      "        -3.0218e-01,  2.1656e-01,  1.3040e-02, -1.4743e-01,  2.3028e-01,\n",
      "         3.6111e-02, -1.3268e-01,  3.4113e-01, -2.3189e-01, -1.9823e-01,\n",
      "        -1.2049e-01, -3.2940e-02, -1.9624e-01,  7.2636e-02, -1.8214e-01,\n",
      "         1.9801e-01, -1.8248e-01,  1.0644e-01, -2.4149e-01, -1.0319e-01,\n",
      "         4.1211e-02,  4.3062e-01, -9.9799e-01, -2.0288e-01,  2.0561e-01,\n",
      "         3.6348e-01, -8.0752e-01, -2.4530e-02,  5.2951e-02, -1.3128e-01,\n",
      "        -3.8987e-01, -1.5092e-01, -1.4595e-01,  3.0709e-01, -1.3847e-01,\n",
      "         2.1710e-01,  5.7917e-02, -2.8042e-01,  7.5014e-01, -1.3664e-01,\n",
      "        -7.1815e-01, -2.8412e-01, -2.2380e-01, -4.9965e-01,  7.1649e-03,\n",
      "         4.6596e-01,  3.5227e-01,  5.9001e-01,  1.0735e+00,  5.9563e-01,\n",
      "         8.3449e-01,  3.0726e-02,  8.1415e-01,  1.3282e+00,  5.9781e-01,\n",
      "         2.8446e-02,  6.3458e-01,  1.2236e+00,  7.0688e-01,  2.8183e-01,\n",
      "         8.7466e-01,  1.6145e+00, -1.7083e-01, -2.7271e-01,  4.7397e-01,\n",
      "        -4.4808e-01,  4.8307e-01,  3.9678e-01,  1.3073e-01,  1.4023e-01,\n",
      "         1.2129e-01, -3.7498e-02,  3.3799e-01, -4.0899e-01,  3.0649e-01,\n",
      "        -3.4444e-01,  4.2282e-01, -1.8000e-01, -2.0687e-01,  8.1184e-01,\n",
      "        -3.1211e-01,  2.6622e-02, -3.9266e-01, -1.7055e-01, -8.6659e-01,\n",
      "        -2.9173e-02,  8.8637e-01, -1.0382e-01,  1.9925e-01,  6.6881e-01,\n",
      "        -4.1964e-01, -7.9390e-01,  1.3054e-01,  2.3315e-01, -3.8470e-01,\n",
      "         1.9958e-01, -4.3514e-02, -3.7880e-01, -5.8399e-01,  2.8911e-01,\n",
      "         3.9766e-02,  8.2827e-01,  1.0028e+00,  4.9720e-01,  3.4211e-01,\n",
      "         4.7429e-01,  5.9036e-01,  4.3777e-01,  1.0254e+00,  7.7785e-01,\n",
      "         3.7887e-01,  2.5416e-01,  4.7323e-01,  1.3385e+00,  1.7336e-01,\n",
      "        -5.0600e-02,  2.4029e-01,  3.1170e-03,  6.5883e-01,  4.0826e-02,\n",
      "         1.5279e-01, -6.2193e-01, -9.8584e-01, -6.4876e-01, -6.0494e-01,\n",
      "        -1.7389e-01,  8.2178e-01,  1.1391e+00,  1.2671e+00,  9.2601e-01,\n",
      "         2.9766e-01,  3.8723e-02,  1.3764e+00,  2.1194e-01,  5.3274e-01,\n",
      "         2.4602e-01, -4.3905e-03, -3.5820e-02,  2.7265e-01, -1.9356e-02,\n",
      "        -9.3578e-01,  3.2190e-01, -3.0394e-01, -3.4573e-01,  4.5849e-01,\n",
      "         1.4501e-01,  4.5298e-01,  1.2096e+00,  8.9756e-01,  3.6772e-01,\n",
      "         1.1986e-01,  2.5483e-01,  1.4477e-01,  6.9181e-01,  3.5083e-01,\n",
      "         4.3399e-01,  4.0948e-02, -3.1488e-01, -3.4395e-01,  3.6061e-02,\n",
      "         2.2324e-01,  1.3074e+00,  6.6028e-01,  3.3385e-01,  7.8579e-02,\n",
      "         5.5116e-01, -1.8433e-01,  4.3198e-01,  4.1956e-01,  8.7609e-01,\n",
      "         1.1585e-01,  1.2022e-01,  1.6238e-01,  7.0899e-02,  9.8278e-01,\n",
      "         1.0394e+00,  1.2428e-01,  1.4936e-01,  1.1842e+00,  6.5863e-01,\n",
      "         3.9570e-01, -7.8263e-01,  3.3517e-01,  4.9871e-01,  3.1796e-01,\n",
      "         2.3508e-01,  5.0320e-01,  5.1497e-01, -1.2074e-02,  3.1983e-01,\n",
      "         1.5859e-01,  3.4979e-01,  5.9433e-01,  2.3757e-01,  9.9277e-02,\n",
      "         1.2768e-01, -4.1908e-01,  7.1980e-01,  8.6540e-01,  5.4483e-01,\n",
      "         2.0420e-01,  4.1413e-01,  3.7850e-01,  7.6697e-01,  1.3356e+00,\n",
      "         1.2928e+00,  1.5709e+00,  1.2580e+00,  2.6353e-01,  5.2276e-01,\n",
      "         4.1084e-01,  3.2157e-01, -2.4052e-01, -2.9175e-01,  1.1303e+00,\n",
      "         1.5869e-01,  2.1965e-01,  5.8022e-01,  2.5209e-01,  3.6791e-01,\n",
      "         1.3181e-01,  1.0815e-01, -4.8520e-02,  7.5054e-01,  6.3979e-01,\n",
      "         3.1038e-01,  7.5353e-02,  7.8570e-01,  4.2911e-01,  4.4248e-01,\n",
      "        -3.1301e-01,  8.2505e-01,  7.7355e-01,  1.3888e+00,  1.5455e+00,\n",
      "         1.0587e+00,  9.6731e-01,  2.0752e-01,  4.7752e-01,  3.4378e-01,\n",
      "         6.8840e-01,  7.9439e-01,  2.8236e-01, -6.0536e-01,  9.3832e-01,\n",
      "         1.3385e+00,  5.6763e-01,  1.0578e+00,  1.0503e+00,  7.2831e-01,\n",
      "         5.9033e-01,  1.0676e+00,  1.1312e+00,  1.1495e+00,  8.0804e-01,\n",
      "         4.5408e-01,  1.4019e-01,  3.7841e-01,  1.2060e+00,  1.2035e-01,\n",
      "         6.7290e-01, -1.7813e-02,  6.5956e-01, -1.8949e-01, -9.7573e-02,\n",
      "        -3.2472e-01,  7.9527e-01, -1.6389e-01,  2.9056e-01,  4.7279e-02,\n",
      "         9.6336e-01,  2.9171e-01,  4.8707e-01,  4.6150e-01,  7.6100e-01,\n",
      "         3.4923e-01,  6.8366e-01,  5.8938e-01,  4.9770e-01,  3.4596e-01,\n",
      "         5.0480e-01, -7.5746e-02,  4.9812e-01,  7.5603e-01,  1.7848e-01,\n",
      "         1.0591e+00,  6.4754e-01,  6.6838e-01,  6.3480e-01,  6.4748e-01,\n",
      "         6.6894e-01,  4.4931e-01,  7.4059e-01,  8.4850e-01, -4.5253e-02,\n",
      "         3.3364e-01, -3.3316e-01, -2.1449e-01, -1.4508e-01,  7.7920e-03,\n",
      "         3.6559e-02, -9.6848e-02,  1.0945e-01, -2.0964e-01, -2.5494e-01,\n",
      "         8.1266e-01,  1.3411e+00,  2.3895e+00,  6.5680e-01,  2.4023e-01,\n",
      "         5.2490e-01,  5.9831e-01, -1.7493e-01,  2.8090e-01,  9.1870e-02,\n",
      "         4.5748e-01,  6.6161e-01,  3.2711e-01,  3.3341e-01,  6.9606e-03,\n",
      "        -5.3167e-01, -7.3207e-02,  3.4023e-01,  3.6804e-01,  1.4350e-01,\n",
      "        -8.3609e-02,  7.3950e-01,  8.6947e-01,  8.0659e-01, -2.3476e-01,\n",
      "         6.4426e-01,  4.6196e-01,  1.0370e-01,  7.9186e-01,  8.4456e-01,\n",
      "        -2.5637e-01,  1.3856e+00,  6.8031e-01,  6.8657e-01,  2.4753e-01,\n",
      "         5.0815e-01,  3.5569e-01,  3.5614e-01,  6.1116e-01,  6.6390e-01,\n",
      "         4.4142e-01,  6.2774e-01,  1.0072e+00,  1.0541e+00,  1.4225e+00,\n",
      "         7.2556e-01, -1.2688e-01,  6.9548e-01,  3.9057e-01,  2.4161e-02,\n",
      "         9.3538e-01,  5.9245e-01,  4.2137e-01,  5.9303e-01,  2.5647e-01,\n",
      "        -3.6217e-01, -6.1758e-02,  1.3282e-01, -1.6785e-01, -4.6702e-01,\n",
      "        -6.2623e-01,  3.5385e-01, -8.0911e-01, -7.1413e-01,  3.4084e-01,\n",
      "         2.2196e-01, -8.3345e-01, -1.9109e-01, -7.3679e-01,  7.4949e-03,\n",
      "        -1.0287e+00, -3.7989e-01,  4.0360e-02, -4.9854e-01, -3.4151e-01,\n",
      "        -3.1515e-02, -1.2077e+00, -1.5372e+00, -9.1114e-01, -4.6522e-01,\n",
      "        -4.2982e-01, -1.9034e-01, -3.5357e-01, -1.9523e-01, -7.6534e-02,\n",
      "        -8.1615e-01, -6.6549e-01,  2.3300e-01, -4.6072e-02, -2.5271e-02,\n",
      "        -1.0414e-01, -5.6377e-01, -9.2190e-01, -6.1776e-01, -1.0402e+00,\n",
      "        -1.2276e+00, -4.3162e-01, -3.4268e-01, -3.6057e-01,  6.0954e-01,\n",
      "        -8.3044e-01, -3.9454e-01,  1.3170e-01,  3.4440e-02, -6.0064e-01,\n",
      "         1.0296e+00, -8.5323e-01, -8.9221e-01, -5.5990e-01, -4.7793e-01,\n",
      "        -7.3933e-01, -6.3922e-01, -6.3718e-01, -3.8374e-01, -3.9501e-01,\n",
      "        -8.8697e-02, -6.3806e-01, -3.9623e-01, -6.4489e-02, -1.0403e+00,\n",
      "         2.1280e-02, -6.8914e-02, -3.0813e-01, -1.0831e+00, -1.2239e+00,\n",
      "        -2.0503e-01,  4.2688e-01, -3.1487e-01, -4.9253e-01, -1.6422e-02,\n",
      "        -1.1225e+00, -1.2497e-01,  4.5691e-01,  7.2140e-02, -4.3199e-01,\n",
      "        -3.9633e-01, -1.6546e-01, -2.0196e-01, -9.4680e-01,  2.2427e-01,\n",
      "        -3.9248e-01, -3.0417e-01, -1.3957e-01, -2.1043e-01, -7.1841e-01,\n",
      "         2.5957e-01, -1.2035e+00, -4.6907e-01, -7.8212e-02,  2.3105e-01,\n",
      "        -5.3389e-01, -5.4368e-01, -7.7741e-01, -1.1462e+00, -2.8882e-01,\n",
      "        -3.4642e-01, -1.4863e-01,  2.3215e-01, -3.8227e-02,  1.1631e-01,\n",
      "         3.5548e-01,  3.7823e-01, -2.6788e-02, -3.8603e-01,  1.0546e-02,\n",
      "        -9.0824e-01, -4.0647e-01, -1.5824e+00, -1.0170e+00, -5.3070e-01,\n",
      "        -1.0517e+00, -2.6831e-01, -9.9906e-02, -5.4257e-01,  2.8108e-01,\n",
      "         6.9791e-03, -7.8949e-01, -3.0663e-01,  1.0567e-01, -9.7025e-01,\n",
      "        -9.7785e-01, -4.6543e-01, -2.2477e-01,  3.1801e-01, -1.6132e-01,\n",
      "         2.0412e-01, -2.7002e-01,  9.4596e-03, -2.0003e-01, -2.2266e-01,\n",
      "        -7.0917e-02, -1.3752e-01,  3.6078e-01,  6.5410e-02, -3.9947e-02,\n",
      "        -9.3460e-01, -9.8906e-01, -1.1412e+00,  7.4281e-02, -5.4457e-01,\n",
      "        -2.6618e-01, -3.1112e-01, -9.0363e-01, -1.3362e-01, -3.2558e-01,\n",
      "         1.1021e-02, -9.4317e-01, -4.0377e-01, -9.9011e-01, -4.9997e-01,\n",
      "        -8.6050e-01, -1.2538e-01,  3.4171e-02, -4.1558e-01, -7.1686e-01,\n",
      "         6.8346e-03,  1.4670e-01, -1.2149e+00, -1.4431e+00, -1.4595e-02,\n",
      "        -1.2782e+00, -1.7504e-01,  2.0720e-01, -1.0459e+00, -5.2051e-03,\n",
      "        -1.2497e+00, -8.6029e-01,  4.3452e-02,  6.6459e-01, -2.6332e-02,\n",
      "        -4.6374e-01, -9.0591e-01, -1.0092e+00, -2.4052e-01, -5.6831e-01,\n",
      "        -8.9753e-01,  1.4560e-01,  1.9711e-01,  8.4323e-02, -8.7470e-01,\n",
      "         3.0135e-01, -7.4463e-01,  1.3779e-01,  5.4590e-03,  4.5827e-01,\n",
      "        -2.2354e-01, -5.2670e-01, -1.8910e-01, -1.5317e-01, -3.9843e-01,\n",
      "        -7.6058e-01, -8.8092e-01, -7.9444e-01, -7.0946e-01,  2.8435e-01,\n",
      "        -7.9956e-01, -3.4968e-01,  2.1585e-01, -3.9652e-01,  5.5635e-02,\n",
      "        -4.4173e-01, -1.1874e-01, -4.4436e-01,  4.1679e-01, -4.3366e-01,\n",
      "        -1.0363e-01, -9.3236e-02, -3.1002e-01, -8.8961e-01, -3.3005e-01,\n",
      "        -1.6758e-02,  7.0147e-01, -7.6138e-01, -5.0144e-01, -2.8520e-01,\n",
      "         1.8344e-01,  1.2086e-01, -3.4433e-01, -1.1425e+00, -8.3285e-01,\n",
      "        -5.4830e-01, -5.7003e-01, -6.5630e-01, -5.1311e-01, -8.2678e-01,\n",
      "        -4.5591e-01, -1.5451e-01, -2.3722e-01,  3.9932e-01, -1.5108e-01,\n",
      "         3.6164e-01,  2.0223e-01, -3.4092e-02,  2.2066e-02, -1.2009e+00,\n",
      "        -3.2421e-01,  4.1079e-02, -9.1950e-01, -1.7270e-01, -8.1763e-02,\n",
      "        -2.5410e-01, -3.2439e-02, -8.8733e-01, -4.2037e-01, -1.4425e+00,\n",
      "        -7.6042e-01, -1.0790e-01, -8.7126e-01, -3.7094e-01, -4.7537e-01,\n",
      "        -6.7541e-01, -1.5252e-02, -9.6645e-01, -3.1847e-01, -5.5523e-02,\n",
      "        -4.7818e-01, -8.2336e-01,  1.9032e-01, -3.4448e-01, -9.8622e-01,\n",
      "         2.9606e-02, -3.2730e-01, -1.2738e-01, -8.6148e-02, -7.5151e-01,\n",
      "        -1.1980e-01, -1.0859e+00,  4.2461e-02, -6.7285e-01,  4.5037e-01,\n",
      "        -1.1529e+00, -1.1683e+00, -9.5996e-02, -1.2273e+00, -6.5688e-01,\n",
      "        -2.8765e-01,  1.2684e-01, -8.5169e-01, -6.9700e-01,  8.1937e-01,\n",
      "        -1.6357e-01,  1.7161e-01, -2.7453e-01,  1.7148e-01,  3.2330e-01,\n",
      "        -1.3582e+00,  6.3060e-01,  3.9907e-01, -3.9703e-01,  2.0854e-01,\n",
      "        -9.0596e-02,  2.3202e-01, -8.9751e-01,  2.3685e-01, -1.3456e-02,\n",
      "        -2.9182e-01, -5.3406e-01, -1.2752e+00, -3.7100e-01, -2.0650e-01,\n",
      "        -7.0041e-01, -2.4943e-01, -5.4672e-01, -1.0442e-01, -5.0383e-01,\n",
      "        -2.7820e-01,  6.5370e-01, -9.5032e-01, -1.1283e+00, -7.1853e-02,\n",
      "         1.4080e-01, -3.6757e-01, -8.6949e-01, -6.3214e-01,  8.8196e-02,\n",
      "        -1.1852e+00, -1.0345e+00, -3.2568e-01, -5.6321e-01, -3.8127e-01,\n",
      "         1.6043e-01, -4.2686e-01,  1.4503e-02, -6.1800e-01,  4.5931e-01,\n",
      "        -2.8172e-01, -6.0364e-01, -9.3259e-01, -7.4031e-01, -1.4208e-01,\n",
      "        -1.7775e-01, -5.9954e-01,  2.8392e-01, -1.5623e-01, -5.1526e-01,\n",
      "        -2.1365e-01, -4.7121e-01, -6.0258e-01,  2.5563e-01, -1.4189e-01,\n",
      "        -4.9604e-01,  3.5783e-01, -7.0949e-01, -1.4412e-01, -9.0303e-01,\n",
      "         4.6820e-01, -9.1344e-01, -3.3810e-01, -2.0960e-01, -2.0819e-01,\n",
      "        -2.3845e-01, -4.0466e-01, -4.7336e-01, -8.3043e-01,  1.3380e-01,\n",
      "        -2.9799e-01,  3.0532e-01, -9.2867e-01,  4.2175e-01,  8.0992e-01,\n",
      "        -2.3321e-01, -2.7512e-01,  3.3728e-01, -3.8673e-02, -5.2585e-01,\n",
      "        -4.1918e-01, -6.5259e-02, -9.3130e-01,  3.3466e-01, -4.7275e-01,\n",
      "        -7.0360e-01,  1.6101e-01, -9.5311e-01, -4.7604e-02, -9.1897e-02,\n",
      "         6.9964e-02, -6.6483e-01, -1.3997e-03,  1.2597e-01,  1.4187e-01,\n",
      "        -1.4943e-01, -1.0168e+00,  4.3417e-01, -3.2049e-02,  4.9000e-02,\n",
      "        -2.8905e-01, -2.9937e-01, -3.4595e-02, -2.2916e-01, -1.0801e+00,\n",
      "        -3.0869e-01, -8.1822e-01, -4.6068e-01,  3.2455e-01,  1.0072e-01,\n",
      "        -2.3470e-01, -7.5748e-01, -1.7862e-01, -3.9699e-01, -5.0633e-01,\n",
      "        -1.0754e-01, -3.8663e-02,  6.3831e-02,  8.3402e-02,  1.2349e+00,\n",
      "         1.8148e-01,  2.2637e-01, -4.0527e-01,  1.3666e-01, -1.0809e+00,\n",
      "        -1.6645e+00, -1.8031e-02, -4.2371e-01, -4.8837e-01, -1.3659e-01,\n",
      "         5.6495e-01, -4.1201e-01, -5.6587e-01, -6.0196e-02,  5.6351e-01,\n",
      "        -2.2485e-01, -4.6314e-01,  3.2496e-02,  7.5757e-01, -3.5430e-01,\n",
      "         2.4435e-01,  4.6865e-01, -1.0966e+00, -2.7814e-01, -5.7138e-01,\n",
      "        -9.9706e-01, -7.9814e-01, -4.8875e-02, -4.6670e-01,  1.7672e-02,\n",
      "        -1.2062e+00,  2.6263e-02, -9.4146e-01,  7.6991e-01, -1.1758e+00,\n",
      "        -4.8980e-01, -6.6501e-01, -4.8999e-01, -5.9271e-01, -7.3375e-01,\n",
      "        -6.5703e-01,  6.9477e-02,  8.7082e-02,  8.3062e-02, -4.2389e-01,\n",
      "         3.5642e-01, -9.4267e-01,  7.5788e-02, -2.7257e-01, -3.3105e-01,\n",
      "         3.9162e-01, -5.3121e-01, -8.1458e-01, -4.6124e-01, -1.0002e-01,\n",
      "        -3.5771e-01, -7.1500e-01,  9.9293e-01, -6.3487e-01, -6.9804e-01,\n",
      "         2.9507e-01, -1.2632e+00, -6.7011e-01, -7.4561e-01,  2.7822e-01,\n",
      "        -1.3435e+00,  5.7700e-01, -3.3516e-01, -5.7322e-01, -1.0345e+00,\n",
      "        -1.1411e+00, -3.1793e-01, -6.8337e-01, -3.4899e-01, -3.9976e-01,\n",
      "        -2.7058e-01, -7.0409e-01,  1.0890e-01, -1.0225e+00, -1.0060e+00,\n",
      "         8.3599e-05,  8.0618e-01, -6.8960e-01, -5.1422e-01,  1.7038e-01,\n",
      "        -2.5589e-02, -5.4900e-01, -1.7796e-01,  1.5816e-02, -6.7100e-01,\n",
      "        -1.3805e-01, -5.0408e-01, -3.5722e-01, -6.1321e-01,  1.2615e-01,\n",
      "        -4.9004e-01, -4.8260e-01,  6.3370e-01, -6.8481e-01, -5.3439e-01,\n",
      "        -2.8244e-01, -7.7767e-02, -3.9712e-01,  1.4742e-01,  5.8644e-01,\n",
      "        -9.2644e-02,  1.5427e-01,  3.1402e-01,  9.5291e-02, -3.7795e-01,\n",
      "        -4.5928e-01, -9.7401e-01, -7.6314e-01, -2.1066e-01,  6.0616e-02,\n",
      "         7.5341e-01,  3.8345e-01, -4.3959e-01, -4.7997e-01, -7.4534e-01,\n",
      "        -3.6766e-01, -8.5159e-01, -9.1465e-01, -3.3119e-01, -5.4149e-01,\n",
      "        -5.0490e-01, -3.6476e-01,  6.1521e-02, -2.4916e-01,  2.6282e-01,\n",
      "         6.9450e-01, -3.4802e-01, -1.8362e-01,  1.8530e-01, -2.0859e-01,\n",
      "         1.4268e-01, -5.5200e-02, -3.2858e-01, -1.8174e-01, -3.1972e-01,\n",
      "         5.7573e-01, -1.1533e-01, -3.0370e-01,  2.8876e-02,  6.8275e-02,\n",
      "         5.6278e-01, -1.9390e-01,  2.6053e-02,  4.2314e-01, -3.0502e-01,\n",
      "        -1.2991e-01, -5.5219e-02, -2.3072e-01,  7.9120e-01,  5.8977e-01,\n",
      "         5.4652e-02,  2.8509e-02, -5.3112e-01, -1.4274e-01,  1.8595e-02,\n",
      "        -2.2184e-01,  1.8855e-01, -5.2292e-03,  7.9378e-02,  9.3386e-02,\n",
      "        -8.7610e-02,  8.7156e-01, -9.5218e-02, -1.3807e-01, -6.1131e-03,\n",
      "        -2.0482e-01, -5.4110e-02,  1.3787e-01,  5.6038e-01, -1.3162e-02,\n",
      "        -6.8153e-01, -4.6555e-02, -1.0807e+00, -1.1343e+00, -6.5341e-01,\n",
      "        -1.0773e+00, -7.9397e-01, -5.5578e-01, -1.1132e+00, -1.0720e+00,\n",
      "        -4.6033e-01, -2.0370e-01, -8.9068e-02, -9.5355e-01, -4.0036e-01,\n",
      "         1.2170e-01, -3.6435e-01,  5.8540e-01, -5.3558e-01, -6.3803e-01,\n",
      "        -3.8231e-01, -5.8692e-02, -4.1444e-01, -7.5415e-01, -4.4174e-01,\n",
      "        -4.0088e-01, -4.4995e-01, -2.7893e-01,  4.8875e-01,  4.1433e-01])\n"
     ]
    }
   ],
   "source": [
    "input_batch = input_tensor.unsqueeze(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)\n",
    "print(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33cc6836-2872-45ec-821d-2262745170bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNeXt(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(32, 96, kernel_size=(4, 4), stride=(4, 4))\n",
       "      (1): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=96, out_features=384, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=384, out_features=96, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "      )\n",
       "      (1): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=96, out_features=384, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=384, out_features=96, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0058823529411764705, mode=row)\n",
       "      )\n",
       "      (2): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=96, out_features=384, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=384, out_features=96, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.011764705882352941, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
       "      (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=192, out_features=768, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=768, out_features=192, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.017647058823529415, mode=row)\n",
       "      )\n",
       "      (1): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=192, out_features=768, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=768, out_features=192, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.023529411764705882, mode=row)\n",
       "      )\n",
       "      (2): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=192, out_features=768, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=768, out_features=192, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.029411764705882353, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.03529411764705883, mode=row)\n",
       "      )\n",
       "      (1): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0411764705882353, mode=row)\n",
       "      )\n",
       "      (2): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.047058823529411764, mode=row)\n",
       "      )\n",
       "      (3): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.052941176470588235, mode=row)\n",
       "      )\n",
       "      (4): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.058823529411764705, mode=row)\n",
       "      )\n",
       "      (5): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.06470588235294118, mode=row)\n",
       "      )\n",
       "      (6): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.07058823529411766, mode=row)\n",
       "      )\n",
       "      (7): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.07647058823529412, mode=row)\n",
       "      )\n",
       "      (8): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0823529411764706, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.08823529411764706, mode=row)\n",
       "      )\n",
       "      (1): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.09411764705882353, mode=row)\n",
       "      )\n",
       "      (2): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): LayerNorm2d((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "    (2): Linear(in_features=768, out_features=32, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change features\n",
    "IN_CHANNELS = 32\n",
    "NUM_CLASSES = 32\n",
    "device = 'cuda'\n",
    "model.features[0][0] = nn.Conv2d(IN_CHANNELS, 96, kernel_size=(4,4), stride=(4,4))\n",
    "model.classifier[2] = nn.Linear(768, NUM_CLASSES)\n",
    "model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62571827-054e-439c-a3ac-b5afcf741ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "NUM_LAYER_LLM = 32\n",
    "\n",
    "class AttentionMapDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, annotations_file, transform=None, target_transform=None):\n",
    "        self.root = Path(root)\n",
    "        self.files = pd.read_csv(annotations_file)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files) * NUM_LAYER_LLM\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        f_idx = int(idx // NUM_LAYER_LLM)\n",
    "        pt_path = self.root / self.files['filename'][f_idx]\n",
    "        f = torch.load(pt_path)\n",
    "        random_layer = idx % NUM_LAYER_LLM\n",
    "        heads = f[random_layer][0]\n",
    "        if self.transform:\n",
    "            heads = self.transform(heads)\n",
    "        bucket_label = int(random_layer // 4)\n",
    "        return heads.to(torch.float32), bucket_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2615e9ab-3129-4306-bab7-3de44088beed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AttentionMapBatchDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, annotations_file, transform=None, target_transform=None):\n",
    "        self.root = Path(root)\n",
    "        self.files = pd.read_csv(annotations_file)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pt_path = self.root / self.files['filename'][idx]\n",
    "        f = torch.load(pt_path)\n",
    "        heads = torch.stack(f).squeeze()\n",
    "        if self.transform:\n",
    "            heads = self.transform(heads)\n",
    "        bucket_labels = torch.arange(NUM_LAYER_LLM)\n",
    "        return heads.to(torch.float32), bucket_labels.to(torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11276af7-97b2-4508-a4ee-3951d2ffec4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import v2 as transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.RandomVerticalFlip(0.5),\n",
    "    transforms.RandomChannelPermutation(),\n",
    "    transforms.Normalize([0.5], [0.25]),\n",
    "])\n",
    "\n",
    "dataset = AttentionMapBatchDataset(Path.home() / \"Downloads/mmlu_output/\", Path.home() / \"Downloads/mmlu_attention_files_list.txt\", transform=transform)\n",
    "\n",
    "# Randomly split into training and test set\n",
    "indices = torch.randperm(len(dataset)).tolist()\n",
    "split_idx = int(len(indices) * 0.8)\n",
    "training_data = torch.utils.data.Subset(dataset, indices[:split_idx])\n",
    "test_data = torch.utils.data.Subset(dataset, indices[split_idx:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9ea085b-520b-4b9b-afbc-ea5f65eb4461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1068, 267)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba0c41c4-d2ff-4b49-999d-7e32bd40a1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(training_data, batch_size=1)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "824676ff-57fc-4a0c-bc53-613cff267b08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sk4835\\AppData\\Local\\Temp\\ipykernel_20008\\560115562.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  f = torch.load(pt_path)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-1.9688, -2.0000, -2.0000,  ..., -1.6094, -0.2891, -0.2578],\n",
       "           [-1.9922, -2.0000, -2.0000,  ...,  1.7656, -1.8906, -2.0000],\n",
       "           [-1.9609, -2.0000, -2.0000,  ...,  0.4531, -2.0000, -2.0000],\n",
       "           ...,\n",
       "           [-1.7266,  1.5938, -1.8672,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [-0.5156,  0.5156, -2.0000,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 2.0000, -2.0000, -2.0000,  ..., -2.0000, -2.0000, -2.0000]],\n",
       " \n",
       "          [[ 1.3906, -2.0000, -2.0000,  ..., -1.9844, -2.0000, -1.9922],\n",
       "           [ 1.1562, -1.9922, -2.0000,  ..., -1.9844, -1.9766, -2.0000],\n",
       "           [ 1.4531, -2.0000, -2.0000,  ..., -1.9766, -2.0000, -2.0000],\n",
       "           ...,\n",
       "           [ 1.4219, -1.7188, -1.7031,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 1.7656, -1.7734, -2.0000,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 2.0000, -2.0000, -2.0000,  ..., -2.0000, -2.0000, -2.0000]],\n",
       " \n",
       "          [[-1.9531, -2.0000, -2.0000,  ..., -1.8828,  0.9688, -1.6094],\n",
       "           [-0.7422, -1.9609, -1.9844,  ..., -1.4688, -1.9453, -2.0000],\n",
       "           [-1.2812, -1.9688, -1.9766,  ..., -1.2031, -2.0000, -2.0000],\n",
       "           ...,\n",
       "           [ 0.8125, -1.0234, -1.7969,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 1.0938, -1.0859, -2.0000,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 2.0000, -2.0000, -2.0000,  ..., -2.0000, -2.0000, -2.0000]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.0000, -2.0000, -2.0000,  ...,  1.0781, -1.7578, -1.9141],\n",
       "           [-1.8828, -2.0000, -1.9922,  ..., -0.1641, -1.6016, -2.0000],\n",
       "           [-1.9766, -2.0000, -2.0000,  ..., -1.1875, -2.0000, -2.0000],\n",
       "           ...,\n",
       "           [ 0.1250, -0.3203, -1.7969,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 0.7969, -0.7891, -2.0000,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 2.0000, -2.0000, -2.0000,  ..., -2.0000, -2.0000, -2.0000]],\n",
       " \n",
       "          [[-1.2188, -1.9844, -2.0000,  ..., -1.6562, -1.9219, -1.8047],\n",
       "           [-1.6250, -1.9766, -2.0000,  ..., -1.7578, -1.9375, -2.0000],\n",
       "           [-1.7578, -1.9609, -2.0000,  ..., -1.7188, -2.0000, -2.0000],\n",
       "           ...,\n",
       "           [ 0.6562, -0.8359, -1.8281,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 0.9219, -0.9219, -2.0000,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 2.0000, -2.0000, -2.0000,  ..., -2.0000, -2.0000, -2.0000]],\n",
       " \n",
       "          [[ 0.1406, -1.9922, -2.0000,  ..., -1.9141, -1.9609, -1.9844],\n",
       "           [ 0.8281, -2.0000, -2.0000,  ..., -1.9844, -2.0000, -2.0000],\n",
       "           [-0.7734, -1.9297, -2.0000,  ..., -1.8906, -2.0000, -2.0000],\n",
       "           ...,\n",
       "           [ 1.5938, -1.6172, -1.9766,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 1.5312, -1.5312, -2.0000,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 2.0000, -2.0000, -2.0000,  ..., -2.0000, -2.0000, -2.0000]]],\n",
       " \n",
       " \n",
       "         [[[-0.6797, -1.3906, -1.9766,  ..., -1.8281, -1.8828, -1.9062],\n",
       "           [-0.4375, -1.4141, -1.9844,  ..., -1.7266, -1.7656, -2.0000],\n",
       "           [-0.8047, -1.1406, -1.9688,  ..., -1.8359, -2.0000, -2.0000],\n",
       "           ...,\n",
       "           [ 0.7031, -0.9531, -1.7500,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 1.9688, -1.9609, -2.0000,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 2.0000, -2.0000, -2.0000,  ..., -2.0000, -2.0000, -2.0000]],\n",
       " \n",
       "          [[ 1.4375, -1.9922, -2.0000,  ..., -1.9688, -1.7031, -1.9219],\n",
       "           [ 1.3906, -1.9922, -2.0000,  ..., -1.9375, -1.8281, -2.0000],\n",
       "           [ 1.2344, -1.9922, -2.0000,  ..., -1.8438, -2.0000, -2.0000],\n",
       "           ...,\n",
       "           [ 1.8750, -1.9688, -1.9062,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 1.9062, -1.9141, -2.0000,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 2.0000, -2.0000, -2.0000,  ..., -2.0000, -2.0000, -2.0000]],\n",
       " \n",
       "          [[ 0.9219, -1.9688, -1.9922,  ..., -1.9766, -1.8828, -1.9531],\n",
       "           [ 1.9062, -2.0000, -2.0000,  ..., -1.9844, -1.9922, -2.0000],\n",
       "           [ 1.2031, -1.9688, -1.9922,  ..., -1.9219, -2.0000, -2.0000],\n",
       "           ...,\n",
       "           [ 1.9219, -1.9531, -1.9688,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 1.9844, -1.9766, -2.0000,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 2.0000, -2.0000, -2.0000,  ..., -2.0000, -2.0000, -2.0000]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.5156, -2.0000, -2.0000,  ..., -1.9062, -1.7266, -1.9219],\n",
       "           [ 1.5469, -2.0000, -2.0000,  ..., -1.7188, -1.8906, -2.0000],\n",
       "           [ 1.3750, -2.0000, -2.0000,  ..., -1.7734, -2.0000, -2.0000],\n",
       "           ...,\n",
       "           [ 1.1562, -1.2500, -1.8984,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 1.8906, -1.8906, -2.0000,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 2.0000, -2.0000, -2.0000,  ..., -2.0000, -2.0000, -2.0000]],\n",
       " \n",
       "          [[ 1.6094, -2.0000, -2.0000,  ..., -1.9609, -1.9141, -1.8281],\n",
       "           [ 1.7031, -2.0000, -2.0000,  ..., -1.9062, -1.9297, -2.0000],\n",
       "           [ 1.7344, -2.0000, -2.0000,  ..., -1.9141, -2.0000, -2.0000],\n",
       "           ...,\n",
       "           [ 1.8438, -1.9375, -1.9062,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 1.8125, -1.8203, -2.0000,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 2.0000, -2.0000, -2.0000,  ..., -2.0000, -2.0000, -2.0000]],\n",
       " \n",
       "          [[-0.2578, -1.9453, -1.9688,  ..., -1.8594, -1.7344, -1.8828],\n",
       "           [-0.9688, -1.8594, -1.9219,  ..., -1.6641, -1.6328, -2.0000],\n",
       "           [-1.2188, -1.9375, -1.9375,  ..., -1.7578, -2.0000, -2.0000],\n",
       "           ...,\n",
       "           [ 0.8438, -1.0625, -1.7812,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 1.8438, -1.8359, -2.0000,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 2.0000, -2.0000, -2.0000,  ..., -2.0000, -2.0000, -2.0000]]],\n",
       " \n",
       " \n",
       "         [[[ 1.9219, -2.0000, -2.0000,  ..., -2.0000, -1.9688, -1.9844],\n",
       "           [ 1.8906, -1.9922, -2.0000,  ..., -2.0000, -1.9766, -2.0000],\n",
       "           [ 1.6719, -2.0000, -2.0000,  ..., -1.9922, -2.0000, -2.0000],\n",
       "           ...,\n",
       "           [ 1.9688, -2.0000, -1.9766,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 1.9844, -1.9844, -2.0000,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 2.0000, -2.0000, -2.0000,  ..., -2.0000, -2.0000, -2.0000]],\n",
       " \n",
       "          [[ 1.9531, -2.0000, -2.0000,  ..., -2.0000, -1.9766, -2.0000],\n",
       "           [ 1.7969, -2.0000, -2.0000,  ..., -1.9922, -1.8672, -2.0000],\n",
       "           [ 1.9375, -2.0000, -2.0000,  ..., -1.9922, -2.0000, -2.0000],\n",
       "           ...,\n",
       "           [ 1.9219, -1.9844, -1.9375,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 1.9688, -1.9688, -2.0000,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 2.0000, -2.0000, -2.0000,  ..., -2.0000, -2.0000, -2.0000]],\n",
       " \n",
       "          [[ 1.6562, -2.0000, -2.0000,  ..., -1.9609, -1.8047, -1.9531],\n",
       "           [ 1.5938, -2.0000, -2.0000,  ..., -1.8906, -1.8438, -2.0000],\n",
       "           [ 1.7188, -2.0000, -2.0000,  ..., -1.8906, -2.0000, -2.0000],\n",
       "           ...,\n",
       "           [ 1.6250, -1.8359, -1.7969,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 1.9062, -1.8984, -2.0000,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 2.0000, -2.0000, -2.0000,  ..., -2.0000, -2.0000, -2.0000]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.9062, -1.9922, -2.0000,  ..., -1.9922, -1.9844, -1.9844],\n",
       "           [ 1.8750, -1.9922, -1.9922,  ..., -1.9922, -1.9844, -2.0000],\n",
       "           [ 1.5156, -1.9531, -1.9922,  ..., -1.9688, -2.0000, -2.0000],\n",
       "           ...,\n",
       "           [ 1.9375, -2.0000, -1.9453,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 1.9688, -1.9766, -2.0000,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 2.0000, -2.0000, -2.0000,  ..., -2.0000, -2.0000, -2.0000]],\n",
       " \n",
       "          [[ 1.7656, -1.9922, -2.0000,  ..., -2.0000, -1.8750, -1.9688],\n",
       "           [ 1.7812, -1.9922, -2.0000,  ..., -1.9922, -1.9375, -2.0000],\n",
       "           [ 1.7656, -1.9922, -1.9922,  ..., -1.9844, -2.0000, -2.0000],\n",
       "           ...,\n",
       "           [ 1.9375, -1.9453, -1.9922,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 1.3594, -1.3516, -2.0000,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 2.0000, -2.0000, -2.0000,  ..., -2.0000, -2.0000, -2.0000]],\n",
       " \n",
       "          [[ 1.9062, -2.0000, -2.0000,  ..., -1.9844, -1.9609, -1.9766],\n",
       "           [ 1.8906, -2.0000, -2.0000,  ..., -1.9766, -1.9688, -2.0000],\n",
       "           [ 1.7656, -2.0000, -2.0000,  ..., -1.9531, -2.0000, -2.0000],\n",
       "           ...,\n",
       "           [ 1.8594, -1.9297, -1.9297,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 1.8594, -1.8594, -2.0000,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 2.0000, -2.0000, -2.0000,  ..., -2.0000, -2.0000, -2.0000]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 1.5938, -1.9922, -1.9766,  ..., -1.9922, -1.9766, -1.9844],\n",
       "           [ 1.5312, -2.0000, -1.9609,  ..., -1.9844, -1.9375, -2.0000],\n",
       "           [ 1.5000, -1.9844, -1.9531,  ..., -1.9922, -2.0000, -2.0000],\n",
       "           ...,\n",
       "           [ 1.9375, -2.0000, -1.9453,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 1.9219, -1.9219, -2.0000,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 2.0000, -2.0000, -2.0000,  ..., -2.0000, -2.0000, -2.0000]],\n",
       " \n",
       "          [[-1.1719, -1.9453, -1.9609,  ..., -1.4844, -1.1875, -1.4688],\n",
       "           [-0.6641, -1.9609, -1.9609,  ..., -1.6406, -0.5547, -2.0000],\n",
       "           [-1.1172, -1.9766, -1.9062,  ..., -0.5938, -2.0000, -2.0000],\n",
       "           ...,\n",
       "           [ 0.2969, -1.5547, -0.7422,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 1.5000, -1.5000, -2.0000,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 2.0000, -2.0000, -2.0000,  ..., -2.0000, -2.0000, -2.0000]],\n",
       " \n",
       "          [[ 1.7969, -2.0000, -2.0000,  ..., -1.9922, -1.8984, -1.9766],\n",
       "           [ 1.7344, -1.9922, -2.0000,  ..., -1.9922, -1.8125, -2.0000],\n",
       "           [ 1.8750, -1.9922, -1.9922,  ..., -1.9922, -2.0000, -2.0000],\n",
       "           ...,\n",
       "           [ 1.9375, -1.9844, -1.9531,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 1.8750, -1.8750, -2.0000,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 2.0000, -2.0000, -2.0000,  ..., -2.0000, -2.0000, -2.0000]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.5938, -2.0000, -1.9922,  ..., -1.9844, -1.8047, -1.9219],\n",
       "           [ 1.3906, -2.0000, -1.9844,  ..., -1.9922, -1.5703, -2.0000],\n",
       "           [ 1.7656, -2.0000, -1.9844,  ..., -1.9766, -2.0000, -2.0000],\n",
       "           ...,\n",
       "           [ 1.9062, -1.9844, -1.9141,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 1.8906, -1.8828, -2.0000,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 2.0000, -2.0000, -2.0000,  ..., -2.0000, -2.0000, -2.0000]],\n",
       " \n",
       "          [[ 1.5938, -2.0000, -2.0000,  ..., -1.9609, -1.6875, -1.9688],\n",
       "           [ 1.2188, -2.0000, -2.0000,  ..., -1.3984, -1.9609, -2.0000],\n",
       "           [ 1.8750, -2.0000, -2.0000,  ..., -1.9531, -2.0000, -2.0000],\n",
       "           ...,\n",
       "           [ 1.2969, -1.3438, -1.9453,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 1.9375, -1.9453, -2.0000,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 2.0000, -2.0000, -2.0000,  ..., -2.0000, -2.0000, -2.0000]],\n",
       " \n",
       "          [[-0.3672, -1.9688, -1.9844,  ..., -1.8594, -1.7500, -1.5156],\n",
       "           [ 0.6094, -1.9688, -1.9766,  ..., -1.8281, -1.6875, -2.0000],\n",
       "           [-1.0312, -1.9688, -1.9609,  ..., -1.8125, -2.0000, -2.0000],\n",
       "           ...,\n",
       "           [ 0.6719, -1.8125, -0.8516,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 1.9375, -1.9375, -2.0000,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 2.0000, -2.0000, -2.0000,  ..., -2.0000, -2.0000, -2.0000]]],\n",
       " \n",
       " \n",
       "         [[[-0.3516, -1.9922, -1.9922,  ..., -1.9453, -1.9453, -1.5781],\n",
       "           [-0.6484, -1.9922, -1.9922,  ..., -1.7188, -1.6562, -2.0000],\n",
       "           [-0.8203, -1.9766, -1.9844,  ..., -1.7031, -2.0000, -2.0000],\n",
       "           ...,\n",
       "           [ 1.5781, -1.9141, -1.6562,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 1.7969, -1.8047, -2.0000,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 2.0000, -2.0000, -2.0000,  ..., -2.0000, -2.0000, -2.0000]],\n",
       " \n",
       "          [[ 0.3125, -1.9844, -1.9609,  ..., -1.9844, -1.8828, -1.9688],\n",
       "           [ 0.5156, -1.9844, -1.9688,  ..., -1.9766, -1.9219, -2.0000],\n",
       "           [ 0.0938, -1.9688, -1.9062,  ..., -1.9766, -2.0000, -2.0000],\n",
       "           ...,\n",
       "           [ 1.9531, -1.9922, -1.9688,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 1.9531, -1.9531, -2.0000,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 2.0000, -2.0000, -2.0000,  ..., -2.0000, -2.0000, -2.0000]],\n",
       " \n",
       "          [[ 1.3125, -1.9922, -1.9844,  ..., -1.9531, -1.8984, -1.8359],\n",
       "           [ 1.3750, -1.9922, -1.9922,  ..., -1.8438, -1.7578, -2.0000],\n",
       "           [ 1.4531, -1.9766, -1.9844,  ..., -1.8672, -2.0000, -2.0000],\n",
       "           ...,\n",
       "           [ 1.7188, -1.9688, -1.7578,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 1.8594, -1.8516, -2.0000,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 2.0000, -2.0000, -2.0000,  ..., -2.0000, -2.0000, -2.0000]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.1250, -1.9844, -1.9922,  ..., -1.9453, -1.7812, -1.2969],\n",
       "           [-0.0156, -1.9766, -1.9766,  ..., -1.9297, -0.8047, -2.0000],\n",
       "           [-0.0078, -1.9531, -1.9688,  ..., -1.0312, -2.0000, -2.0000],\n",
       "           ...,\n",
       "           [ 1.0938, -1.9453, -1.1484,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [-0.5547,  0.5625, -2.0000,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 2.0000, -2.0000, -2.0000,  ..., -2.0000, -2.0000, -2.0000]],\n",
       " \n",
       "          [[-0.6641, -1.9922, -1.9922,  ..., -1.9688, -1.2812, -0.7109],\n",
       "           [-0.5000, -1.9844, -1.9844,  ..., -1.9297, -0.5234, -2.0000],\n",
       "           [-0.8203, -1.9766, -1.9844,  ..., -1.2344, -2.0000, -2.0000],\n",
       "           ...,\n",
       "           [ 0.6875, -1.9688, -0.7266,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 0.8438, -0.8516, -2.0000,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 2.0000, -2.0000, -2.0000,  ..., -2.0000, -2.0000, -2.0000]],\n",
       " \n",
       "          [[ 1.1719, -1.9766, -2.0000,  ..., -1.9453, -1.9609, -1.8750],\n",
       "           [ 1.1094, -1.9766, -2.0000,  ..., -1.8594, -1.8281, -2.0000],\n",
       "           [ 1.0469, -1.9688, -1.9922,  ..., -1.8594, -2.0000, -2.0000],\n",
       "           ...,\n",
       "           [ 1.9531, -1.9766, -1.9766,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 1.8750, -1.8672, -2.0000,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 2.0000, -2.0000, -2.0000,  ..., -2.0000, -2.0000, -2.0000]]],\n",
       " \n",
       " \n",
       "         [[[ 0.3438, -2.0000, -1.9922,  ..., -1.9297, -1.7969, -0.8750],\n",
       "           [ 0.3906, -1.9922, -1.9922,  ..., -1.7188, -1.0469, -2.0000],\n",
       "           [-0.7500, -1.9844, -1.9844,  ...,  0.0938, -2.0000, -2.0000],\n",
       "           ...,\n",
       "           [ 0.6406, -1.8828, -0.7578,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [-0.9844,  0.9844, -2.0000,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 2.0000, -2.0000, -2.0000,  ..., -2.0000, -2.0000, -2.0000]],\n",
       " \n",
       "          [[-0.3516, -1.9922, -1.5156,  ..., -1.9688, -1.8906, -1.9531],\n",
       "           [-0.1094, -1.9844, -1.7188,  ..., -1.8906, -1.8672, -2.0000],\n",
       "           [-0.0078, -1.9766, -1.4219,  ..., -1.9219, -2.0000, -2.0000],\n",
       "           ...,\n",
       "           [ 0.7656, -1.9062, -0.8594,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 1.4688, -1.4688, -2.0000,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 2.0000, -2.0000, -2.0000,  ..., -2.0000, -2.0000, -2.0000]],\n",
       " \n",
       "          [[-0.8438, -2.0000, -1.9922,  ..., -1.8047, -1.8281, -0.7578],\n",
       "           [-0.7344, -2.0000, -1.9844,  ..., -1.4609, -1.7344, -2.0000],\n",
       "           [-0.9922, -1.9922, -1.9922,  ..., -0.9219, -2.0000, -2.0000],\n",
       "           ...,\n",
       "           [ 0.4375, -1.8438, -0.5938,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 1.3125, -1.3125, -2.0000,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 2.0000, -2.0000, -2.0000,  ..., -2.0000, -2.0000, -2.0000]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.7500, -2.0000, -1.9922,  ..., -1.8594, -1.7500, -0.0938],\n",
       "           [-0.9297, -2.0000, -1.9844,  ..., -1.4688,  0.0312, -2.0000],\n",
       "           [-0.2734, -1.9844, -1.9766,  ..., -0.8203, -2.0000, -2.0000],\n",
       "           ...,\n",
       "           [ 0.2344, -1.7891, -0.4453,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 0.6250, -0.6328, -2.0000,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 2.0000, -2.0000, -2.0000,  ..., -2.0000, -2.0000, -2.0000]],\n",
       " \n",
       "          [[ 0.7031, -1.9922, -1.9844,  ..., -1.8516, -1.8906, -1.3438],\n",
       "           [ 1.3125, -2.0000, -1.9922,  ..., -1.8828, -1.7109, -2.0000],\n",
       "           [ 0.2188, -1.9453, -1.9844,  ..., -0.6016, -2.0000, -2.0000],\n",
       "           ...,\n",
       "           [ 1.6719, -1.9219, -1.7500,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [-1.7891,  1.7969, -2.0000,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 2.0000, -2.0000, -2.0000,  ..., -2.0000, -2.0000, -2.0000]],\n",
       " \n",
       "          [[-0.8125, -1.9922, -1.9922,  ..., -1.5625, -1.4375, -1.2812],\n",
       "           [-0.6719, -2.0000, -1.9922,  ..., -1.2891, -0.9219, -2.0000],\n",
       "           [-0.5469, -1.9609, -1.9375,  ..., -1.5234, -2.0000, -2.0000],\n",
       "           ...,\n",
       "           [ 0.4688, -1.8203, -0.6484,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 1.8125, -1.8125, -2.0000,  ..., -2.0000, -2.0000, -2.0000],\n",
       "           [ 2.0000, -2.0000, -2.0000,  ..., -2.0000, -2.0000, -2.0000]]]],\n",
       "        device='cuda:0', grad_fn=<ToCopyBackward0>),\n",
       " tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c71d779e-7b9d-44f0-aa00-ced9abeaae2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sk4835\\AppData\\Local\\Temp\\ipykernel_20008\\560115562.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  f = torch.load(pt_path)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0205,  0.1398,  0.1044,  ...,  0.2152, -0.2854, -0.0206],\n",
       "        [-0.1604,  0.2341,  0.1607,  ...,  0.3198, -0.2941,  0.0870],\n",
       "        [ 0.0227,  0.1755, -0.0862,  ...,  0.2575, -0.1685,  0.1081],\n",
       "        ...,\n",
       "        [-0.0512,  0.2394,  0.0767,  ...,  0.3011, -0.2062,  0.0551],\n",
       "        [-0.0148,  0.1947,  0.0511,  ...,  0.2493, -0.2675, -0.0404],\n",
       "        [-0.1721,  0.1384,  0.1960,  ...,  0.3207,  0.0209,  0.0763]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(training_data.__getitem__(0)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b5b3e2d-2168-4412-8a8f-acb05d85720b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "from tqdm import tqdm\n",
    "NUM_CLASSES = 32\n",
    "accuracy = torchmetrics.Accuracy(task='multiclass', num_classes=NUM_CLASSES).to(device)\n",
    "recall = torchmetrics.Recall(task='multiclass', num_classes=NUM_CLASSES).to(device)\n",
    "precision = torchmetrics.Precision(task='multiclass', num_classes=NUM_CLASSES).to(device)\n",
    "auroc = torchmetrics.AUROC(task='multiclass', num_classes=NUM_CLASSES).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b03f3e-f12d-4f60-a303-623267d28fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sk4835\\AppData\\Local\\Temp\\ipykernel_20008\\560115562.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  f = torch.load(pt_path)\n",
      "Training:  21%|                                                      | 229/1068 [02:10<03:51,  3.62it/s]"
     ]
    }
   ],
   "source": [
    "params = model.parameters()\n",
    "optimizer = torch.optim.Adam(params, lr=5e-2)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.5)\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    tr_loss = 0\n",
    "    nb_tr_steps = 0\n",
    "    for x, y in tqdm(train_dataloader, desc='Training: '):\n",
    "        x = x.squeeze().to(device)\n",
    "        y = y.squeeze().to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        try:\n",
    "            logits = model(x)\n",
    "        except Exception as e:\n",
    "            print(x.shape, y)\n",
    "            raise e\n",
    "\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_steps += 1\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f'Epoch {epoch}: Training Loss:', tr_loss / nb_tr_steps)\n",
    "\n",
    "    model.eval()\n",
    "    val_acc = []\n",
    "    val_prec = []\n",
    "    val_rec = []\n",
    "    val_auroc = []\n",
    "    for x, y in tqdm(test_dataloader, desc='Validation'):\n",
    "        x = x.squeeze().to(device)\n",
    "        y = y.squeeze().to(device)\n",
    "        \n",
    "        logits = model(x)\n",
    "        prediction = torch.argmax(logits, dim=-1)\n",
    "\n",
    "        val_acc.append(accuracy(prediction, y))\n",
    "        val_prec.append(precision(prediction, y))\n",
    "        val_rec.append(recall(prediction, y))\n",
    "        # val_auroc.append(auroc(prediction, y))\n",
    "\n",
    "    print(f'Epoch {epoch}: Validation Accuracy:', sum(val_acc) / len(val_acc))\n",
    "    print(f'Epoch {epoch}: Validation Precision:', sum(val_prec) / len(val_prec))\n",
    "    print(f'Epoch {epoch}: Validation Recall:', sum(val_rec) / len(val_rec))\n",
    "    # print(f'Epoch {epoch}: Validation AUROC:', sum(val_auroc) / len(val_auroc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "efb1f03d-a7d0-4bf5-99a7-bfec49f6dfa8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNeXt(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(1024, 96, kernel_size=(4, 4), stride=(4, 4))\n",
       "      (1): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=96, out_features=384, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=384, out_features=96, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "      )\n",
       "      (1): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=96, out_features=384, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=384, out_features=96, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0058823529411764705, mode=row)\n",
       "      )\n",
       "      (2): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=96, out_features=384, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=384, out_features=96, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.011764705882352941, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
       "      (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=192, out_features=768, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=768, out_features=192, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.017647058823529415, mode=row)\n",
       "      )\n",
       "      (1): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=192, out_features=768, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=768, out_features=192, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.023529411764705882, mode=row)\n",
       "      )\n",
       "      (2): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=192, out_features=768, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=768, out_features=192, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.029411764705882353, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.03529411764705883, mode=row)\n",
       "      )\n",
       "      (1): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0411764705882353, mode=row)\n",
       "      )\n",
       "      (2): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.047058823529411764, mode=row)\n",
       "      )\n",
       "      (3): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.052941176470588235, mode=row)\n",
       "      )\n",
       "      (4): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.058823529411764705, mode=row)\n",
       "      )\n",
       "      (5): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.06470588235294118, mode=row)\n",
       "      )\n",
       "      (6): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.07058823529411766, mode=row)\n",
       "      )\n",
       "      (7): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.07647058823529412, mode=row)\n",
       "      )\n",
       "      (8): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0823529411764706, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.08823529411764706, mode=row)\n",
       "      )\n",
       "      (1): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.09411764705882353, mode=row)\n",
       "      )\n",
       "      (2): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): LayerNorm2d((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "    (2): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torchvision.models.convnext_tiny(weights=convnext.ConvNeXt_Tiny_Weights.DEFAULT)\n",
    "# Change features\n",
    "IN_CHANNELS = 32*32\n",
    "device = 'cuda'\n",
    "model.features[0][0] = nn.Conv2d(IN_CHANNELS, 96, kernel_size=(4,4), stride=(4,4))\n",
    "model.classifier[2] = nn.Linear(768, 2)\n",
    "model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ff760250-a4fd-4680-90f7-9b846933d103",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AllAttentionMapDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, annotations_file, transform=None, target_transform=None):\n",
    "        self.root = Path(root)\n",
    "        self.files = pd.read_csv(annotations_file)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.files.iloc[idx]\n",
    "        pt_path = self.root / item['filename']\n",
    "        heads = torch.load(pt_path)\n",
    "        heads = torch.stack(heads, dim=0).flatten(start_dim=0, end_dim=2)  # 2 is exclusive, only flattens dim0 and dim1\n",
    "        if self.transform:\n",
    "            heads = self.transform(heads)\n",
    "        return heads.to(torch.float32), torch.tensor(item['prediction'] == item['correct']).to(torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a3f71ddf-6103-4d83-b91c-8acfb2e7b8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import v2 as transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.RandomVerticalFlip(0.5),\n",
    "    transforms.RandomChannelPermutation(),\n",
    "    transforms.Normalize([0.5], [0.25]),\n",
    "])\n",
    "\n",
    "# dataset = AttentionMapDataset(Path.home() / \"Downloads/mmlu_output/\", Path.home() / \"Downloads/mmlu_attention_files_list.txt\", transform=transform)\n",
    "dataset = AllAttentionMapDataset(Path.home() / \"Downloads/mmlu_output/\", Path.home() / \"Downloads/mmlu_attention_files_list.txt\", transform=transform)\n",
    "\n",
    "# Randomly split into training and test set\n",
    "indices = torch.randperm(len(dataset)).tolist()\n",
    "split_idx = int(len(indices) * 0.8)\n",
    "training_data = torch.utils.data.Subset(dataset, indices[:split_idx])\n",
    "test_data = torch.utils.data.Subset(dataset, indices[split_idx:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2ec5b3f1-4612-4413-960d-aeaa0d7cd54c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1068, 267)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "497bfe59-fcd2-4bf6-ad7d-e10d86e8270f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(training_data, batch_size=1)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8f016950-0650-4604-b66a-003184861ed9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sk4835\\AppData\\Local\\Temp\\ipykernel_16524\\4137315560.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  heads = torch.load(pt_path)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 55, 55])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.__getitem__(0)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b641a899-4904-4259-b8e7-c20e701f16f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sk4835\\AppData\\Local\\Temp\\ipykernel_16524\\4137315560.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  heads = torch.load(pt_path)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2379, -0.0539]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(training_data.__getitem__(0)[0].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9ff780c0-b312-4530-9190-02833f5a8977",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "from tqdm import tqdm\n",
    "accuracy = torchmetrics.Accuracy(task='binary').to(device)\n",
    "recall = torchmetrics.Recall(task='binary').to(device)\n",
    "precision = torchmetrics.Precision(task='binary').to(device)\n",
    "auroc = torchmetrics.AUROC(task='binary').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "39a3dc7d-2b4e-44d5-85be-3e07c79f5ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sk4835\\AppData\\Local\\Temp\\ipykernel_16524\\4137315560.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  heads = torch.load(pt_path)\n",
      "\n",
      "raining: 100%|| 1068/1068 [01:09<00:00, 15.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Training Loss: 1.415288276960271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "alidation: 100%|| 267/267 [00:10<00:00, 24.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Validation Accuracy: tensor(0.5768, device='cuda:0')\n",
      "Epoch 0: Validation Precision: tensor(0.3071, device='cuda:0')\n",
      "Epoch 0: Validation Recall: tensor(0.3071, device='cuda:0')\n",
      "Epoch 0: Validation AUROC: tensor(0., device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "raining: 100%|| 1068/1068 [01:09<00:00, 15.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Training Loss: 1.3076700279855575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "alidation: 100%|| 267/267 [00:12<00:00, 20.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Validation Accuracy: tensor(0.5768, device='cuda:0')\n",
      "Epoch 1: Validation Precision: tensor(0.3071, device='cuda:0')\n",
      "Epoch 1: Validation Recall: tensor(0.3071, device='cuda:0')\n",
      "Epoch 1: Validation AUROC: tensor(0., device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "raining: 100%|| 1068/1068 [01:08<00:00, 15.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Training Loss: 0.690339772302783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "alidation: 100%|| 267/267 [00:14<00:00, 17.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Validation Accuracy: tensor(0.5768, device='cuda:0')\n",
      "Epoch 2: Validation Precision: tensor(0.3071, device='cuda:0')\n",
      "Epoch 2: Validation Recall: tensor(0.3071, device='cuda:0')\n",
      "Epoch 2: Validation AUROC: tensor(0., device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "raining: 100%|| 1068/1068 [01:08<00:00, 15.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Training Loss: 0.6880884663889024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "alidation: 100%|| 267/267 [00:17<00:00, 15.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Validation Accuracy: tensor(0.5768, device='cuda:0')\n",
      "Epoch 3: Validation Precision: tensor(0.3071, device='cuda:0')\n",
      "Epoch 3: Validation Recall: tensor(0.3071, device='cuda:0')\n",
      "Epoch 3: Validation AUROC: tensor(0., device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "raining: 100%|| 1068/1068 [01:08<00:00, 15.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Training Loss: 0.6843108450540443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "alidation: 100%|| 267/267 [00:19<00:00, 13.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Validation Accuracy: tensor(0.5768, device='cuda:0')\n",
      "Epoch 4: Validation Precision: tensor(0.3071, device='cuda:0')\n",
      "Epoch 4: Validation Recall: tensor(0.3071, device='cuda:0')\n",
      "Epoch 4: Validation AUROC: tensor(0., device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "raining: 100%|| 1068/1068 [01:08<00:00, 15.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Training Loss: 0.6842318316189091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "alidation: 100%|| 267/267 [00:21<00:00, 12.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Validation Accuracy: tensor(0.5768, device='cuda:0')\n",
      "Epoch 5: Validation Precision: tensor(0.3071, device='cuda:0')\n",
      "Epoch 5: Validation Recall: tensor(0.3071, device='cuda:0')\n",
      "Epoch 5: Validation AUROC: tensor(0., device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "raining: 100%|| 1068/1068 [01:08<00:00, 15.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Training Loss: 0.6836288277241175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "alidation: 100%|| 267/267 [00:23<00:00, 11.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Validation Accuracy: tensor(0.5768, device='cuda:0')\n",
      "Epoch 6: Validation Precision: tensor(0.3071, device='cuda:0')\n",
      "Epoch 6: Validation Recall: tensor(0.3071, device='cuda:0')\n",
      "Epoch 6: Validation AUROC: tensor(0., device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "raining:   6%|                                                                  | 62/1068 [00:03<01:02, 16.17it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[95], line 23\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m     21\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(logits, y)\n\u001b[1;32m---> 23\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     27\u001b[0m tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\llama-env\\lib\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\llama-env\\lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\llama-env\\lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    827\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params = model.parameters()\n",
    "optimizer = torch.optim.Adam(params, lr=5e-2)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    tr_loss = 0\n",
    "    nb_tr_steps = 0\n",
    "    for x, y in tqdm(train_dataloader, desc='Training: '):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        try:\n",
    "            logits = model(x)\n",
    "        except Exception as e:\n",
    "            print(x.shape, y, f)\n",
    "            raise e\n",
    "\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_steps += 1\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f'Epoch {epoch}: Training Loss:', tr_loss / nb_tr_steps)\n",
    "\n",
    "    model.eval()\n",
    "    val_acc = []\n",
    "    val_prec = []\n",
    "    val_rec = []\n",
    "    val_auroc = []\n",
    "    for x, y in tqdm(test_dataloader, desc='Validation'):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        logits = model(x)\n",
    "        prediction = torch.argmax(logits, dim=-1)\n",
    "\n",
    "        val_acc.append(accuracy(prediction, y))\n",
    "        val_prec.append(precision(prediction, y))\n",
    "        val_rec.append(recall(prediction, y))\n",
    "        val_auroc.append(auroc(prediction, y))\n",
    "\n",
    "    print(f'Epoch {epoch}: Validation Accuracy:', sum(val_acc) / len(val_acc))\n",
    "    print(f'Epoch {epoch}: Validation Precision:', sum(val_prec) / len(val_prec))\n",
    "    print(f'Epoch {epoch}: Validation Recall:', sum(val_rec) / len(val_rec))\n",
    "    print(f'Epoch {epoch}: Validation AUROC:', sum(val_auroc) / len(val_auroc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c686ce1-539c-4eb8-aa8e-71ad77c53db9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
